{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Explicabilité - SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "**Auteur:** Sandie Cabon  \n",
    "**Date:** 2 février 2026\n",
    "\n",
    "Ce notebook permet d'utiliser SHAP pour expliquer les prédictions du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helping_functions_et import infer_column_types\n",
    "import joblib\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration (NE PAS MODIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### CHARGEMENT DES DONNÉES #####################\")\n",
    "\n",
    "# close older figures\n",
    "plt.close(\"all\")\n",
    "\n",
    "# load heart failure dataset\n",
    "dataset = pd.read_csv(\"heart_failure_dataset_test.csv\")\n",
    "\n",
    "# apply good type to dataframe (custom function)\n",
    "dataset = infer_column_types(dataset)\n",
    "\n",
    "# separate feat and target values\n",
    "dataset_feat = dataset.drop(\"DEATH_EVENT\", axis=1)\n",
    "dataset_target = dataset[\"DEATH_EVENT\"]\n",
    "feat_names = list(dataset_feat.columns)\n",
    "\n",
    "# load the pipeline (composed by a preprocessor and a model)\n",
    "loaded_RF = joblib.load('death_RF_predictor.pkl')\n",
    "\n",
    "preprocessor = loaded_RF.named_steps['preprocessor']\n",
    "model = loaded_RF.named_steps['model']\n",
    "\n",
    "# settings for reproducibility\n",
    "random_state = 12\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. SHAP (SHapley Additive exPlanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données et calcul des SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ V. SHAP (SHapley Additive exPlanations) ############\")\n",
    "\n",
    "# Les fonctions de Shap ne prennent pas en charge le preprocessing (mise à l'echelle). \n",
    "# Il faut donc le faire en amont\n",
    "# Effectuer le prétraitement manuellement sur les données de test\n",
    "# aide : utiliser la fonction transfrom du preprocessor sur le dataFrame contenant les variables\n",
    "feat_scaled = [] # à modifier\n",
    "dataset_scaled = pd.DataFrame(feat_scaled, columns=feat_names)\n",
    "dataset_scaled = infer_column_types(dataset_scaled)\n",
    "\n",
    "# Créer un objet explainer SHAP en utilidans \n",
    "explainer = shap.Explainer(model)\n",
    "# Calculer les Shapley values pour l'ensemble de test\n",
    "# shap_values = explainer.shap_values(dataset_scaled) # à décommenter quand le dataset_scaled est prêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix de la méthode\n",
    "\n",
    "Nommer la methode pour executer la bonne partie du code : \"summary\", \"beeswarm\", \"waterfall\" or \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nommer la methode pour executer la bonne partie du code : \"summary\", \"beeswarm\", \"waterfall\" or \"all\"\n",
    "method = \"summary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary plot\n",
    "compléter la fonction shap.summary_plot() https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"summary\" or method == \"all\":\n",
    "    # generation du graphe\n",
    "    # compléter la fonction shap.summary_plot() https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html\n",
    "    plt.figure()\n",
    "    #shap.summary_plot(..., ..., plot_type=\"bar\") \n",
    "    plt.tight_layout()\n",
    "    plt.title('Summary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beeswarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"beeswarm\" or method == \"all\":\n",
    "    shap_values = explainer(dataset_scaled)\n",
    "    \n",
    "    # generation du graphe\n",
    "    shap.plots.beeswarm(shap_values[:,:,1], max_display=15)\n",
    "    plt.tight_layout()\n",
    "    plt.title('Beeswarm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterfall plot pour une observation spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"waterfall\" or method == \"all\":\n",
    "    # choix de l'observation à étudier. Renseigner l'index.\n",
    "    obs_index = ...\n",
    "    print(\"Le label associé à cette observation est : %s \" %dataset_target[obs_index])\n",
    "    \n",
    "    # generation du graphe\n",
    "    # compléter la fonction shap.plots.waterfall\n",
    "    plt.figure()\n",
    "    shap.plots.waterfall(shap_values=shap_values[..., :,1],\n",
    "                         max_display=20,show=False)\n",
    "    \n",
    "    plt.title(f'SHAP effects Observation {obs_index}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes et Aides\n",
    "\n",
    "### AIDE 1\n",
    "Les fonctions de Shap ne prennent pas en charge le preprocessing (mise à l'echelle). \n",
    "Dans les affichages, nous observons donc les valeurs mises à l'echelle. \n",
    "Cela rends plus difficile l'interprétation.\n",
    "\n",
    "Vous pouvez utiliser la fonction `get_original_value(idx, feat_name, original_data)`\n",
    "qui vous permettra de convertir une valeur mise à l'echelle en sa valeur originale.\n",
    "Importer là au préalable. Vous pourrez ensuite l'executer dans la console.\n",
    "\n",
    "### AIDE 2\n",
    "Pour selectionner des erreurs de type Faux Négatifs, Faux Positifs:\n",
    "- Utiliser la méthode `predict()` de model sur les données mises à l'échelle\n",
    "- Ou utiliser la méthode `predict()` du pipeline (loaded_RF) sur les données originales\n",
    "- Comparer avec le contenu de la variable `dataset_target` pour trouver des observations d'intérêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
